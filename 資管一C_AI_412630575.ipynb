{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPp165LGG0Wvq1gC57TcGwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heyyugoodbro/TKU-AI-412630575/blob/main/%E8%B3%87%E7%AE%A1%E4%B8%80C_AI_412630575.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI1pp1S9NsAA",
        "outputId": "69b66bf0-6129-4c81-bf22-3a8a1e57098c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAMOc8PEEpQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "9in48j7hUgFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iGmvAIB9VlsZ",
        "outputId": "a0c19cf9-05c9-46a5-af1c-7ff41d571b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.13.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_E3dzDUVsaH",
        "outputId": "11a7b6c8-ba72-42a6-f60d-7d011d7928df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prkfd2lqV-Ts",
        "outputId": "0d398445-2df8-4d9c-d9df-99b526dd04d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  2 12:24:06 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    27W /  70W |    359MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ORC"
      ],
      "metadata": {
        "id": "82qCv8VtKe6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-orc\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N8q3nmmfnq0",
        "outputId": "b32a6e88-a173-4432-8e18-d492f71cf1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package tesseract-orc\u001b[0m\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ],
      "metadata": {
        "id": "9TEegwKzgXZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded =files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "kv5Mkuf2hdD1",
        "outputId": "018f15c1-3556-456e-bf2f-e128d389b5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de6b3068-2ca1-47f0-b3c6-5a670f80faa9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de6b3068-2ca1-47f0-b3c6-5a670f80faa9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cba8b5e6-1005-4e40-bf6c-5a5b0b555ef9.jpg to cba8b5e6-1005-4e40-bf6c-5a5b0b555ef9.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_in_colab=\"cba8b5e6-1005-4e40-bf6c-5a5b0b555ef9.jpg\"\n",
        "extractedInformation = pytesseract.image_to_string(Image.open(image_path_in_colab))\n",
        "print(extractedInformation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "_M1qEJwcjbiC",
        "outputId": "d5b43e8a-7ba2-4d7b-d1c8-6e4cb576c04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f4dc3bc1b078>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_path_in_colab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cba8b5e6-1005-4e40-bf6c-5a5b0b555ef9.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mextractedInformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path_in_colab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextractedInformation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pytesseract' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytesseract"
      ],
      "metadata": {
        "id": "gfPm-I66FhMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb5A0x_CErDl",
        "outputId": "b2ea76e0-d9d6-41c2-e653-ee28c0ea0f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1st attempt"
      ],
      "metadata": {
        "id": "qWnak2L5MkFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "image = cv2.imread('1.jpg')\n",
        "\n",
        "\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "\n",
        "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
        "\n",
        "plate_contour = None\n",
        "\n",
        "for contour in contours:\n",
        "    perimeter = cv2.arcLength(contour, True)\n",
        "    approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
        "    if len(approx) == 4:\n",
        "        plate_contour = approx\n",
        "        break\n",
        "\n",
        "\n",
        "if plate_contour is not None:\n",
        "    mask = np.zeros(gray.shape, np.uint8)\n",
        "    cv2.drawContours(mask, [plate_contour], 0, (255, 255, 255), -1)\n",
        "    masked_image = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    cv2.imshow('Original Image', image)\n",
        "    cv2.imshow('Plate', masked_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "LlIKECSHEskV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-cRZyfrJeEA",
        "outputId": "ece956b0-df3b-4de5-cf6f-97221743e480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Tesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BWUOmI0JyWT",
        "outputId": "d2681fa9-e2bc-4087-ac53-443ff75ad4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Tesseract\n",
            "  Downloading tesseract-0.1.3.tar.gz (45.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Tesseract\n",
            "  Building wheel for Tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Tesseract: filename=tesseract-0.1.3-py3-none-any.whl size=45562550 sha256=38a03579d6b44406f0d167b32e71839af344ced926cdc382ccbafd766305bb76\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c9/aa/698c579693e83fdda9ad6d6f0d8f61ed986e27925ef576f109\n",
            "Successfully built Tesseract\n",
            "Installing collected packages: Tesseract\n",
            "Successfully installed Tesseract-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd attempt"
      ],
      "metadata": {
        "id": "jAd4GehXMqpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "\n",
        "# 讀取圖像\n",
        "image = cv2.imread('1.jpg')\n",
        "\n",
        "# 圖像預處理\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "# 車牌定位\n",
        "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
        "\n",
        "plate_contour = None\n",
        "\n",
        "for contour in contours:\n",
        "    perimeter = cv2.arcLength(contour, True)\n",
        "    approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
        "    if len(approx) == 4:\n",
        "        plate_contour = approx\n",
        "        break\n",
        "\n",
        "# 字符分割和識別\n",
        "if plate_contour is not None:\n",
        "    mask = np.zeros(gray.shape, np.uint8)\n",
        "    cv2.drawContours(mask, [plate_contour], 0, (255, 255, 255), -1)\n",
        "    masked_image = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "\n",
        "    # 使用Tesseract進行OCR\n",
        "    text = pytesseract.image_to_string(masked_image, config='--psm 7')\n",
        "\n",
        "    # 顯示結果\n",
        "    cv2.imshow('Original Image', image)\n",
        "    cv2.imshow('Plate', masked_image)\n",
        "    print('識別結果:', text)\n",
        "\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "uui7Co9tJP_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3rd attempt"
      ],
      "metadata": {
        "id": "inKIEUDiM01L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "\n",
        "# 讀取圖像\n",
        "image = cv2.imread('1.jpg')\n",
        "\n",
        "# 圖像預處理\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "# 車牌定位\n",
        "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
        "\n",
        "plate_contour = None\n",
        "\n",
        "for contour in contours:\n",
        "    perimeter = cv2.arcLength(contour, True)\n",
        "    approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
        "    if len(approx) == 4:\n",
        "        plate_contour = approx\n",
        "        break\n",
        "\n",
        "# 字符分割和識別\n",
        "if plate_contour is not None:\n",
        "    mask = np.zeros(gray.shape, np.uint8)\n",
        "    cv2.drawContours(mask, [plate_contour], 0, (255, 255, 255), -1)\n",
        "    masked_image = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "\n",
        "    # 使用Tesseract進行OCR\n",
        "    custom_config = r'--oem 3 --psm 7'\n",
        "    text = pytesseract.image_to_string(masked_image, config=custom_config)\n",
        "\n",
        "    # 顯示結果\n",
        "    cv2.imshow('Original Image', image)\n",
        "    cv2.imshow('Plate', masked_image)\n",
        "    print('識別結果:', text)\n",
        "\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5eLI8dlhLWAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4th attempt"
      ],
      "metadata": {
        "id": "s7ha5eZrMzB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "\n",
        "# 讀取圖像\n",
        "image = cv2.imread('1.jpg')\n",
        "\n",
        "# 圖像預處理\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "edges = cv2.Canny(blur, 50, 150)\n",
        "\n",
        "# 車牌定位\n",
        "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
        "\n",
        "plate_contour = None\n",
        "\n",
        "for contour in contours:\n",
        "    perimeter = cv2.arcLength(contour, True)\n",
        "    approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
        "    if len(approx) == 4:\n",
        "        plate_contour = approx\n",
        "        break\n",
        "\n",
        "# 字符分割和識別\n",
        "if plate_contour is not None:\n",
        "    mask = np.zeros(gray.shape, np.uint8)\n",
        "    cv2.drawContours(mask, [plate_contour], 0, (255, 255, 255), -1)\n",
        "    masked_image = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "\n",
        "    # 使用Tesseract進行OCR\n",
        "    custom_config = r'--oem 3 --psm 7'\n",
        "    text = pytesseract.image_to_string(masked_image, config=custom_config)\n",
        "\n",
        "    # 在圖像上顯示識別結果\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(image, '識別結果: ' + text, (10, 30), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # 顯示結果\n",
        "    cv2.imshow('Original Image', image)\n",
        "    cv2.imshow('Plate', masked_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "ORZ8ekuAMV8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5"
      ],
      "metadata": {
        "id": "RAsQSy0BOR2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "\n",
        "# 圖像預處理\n",
        "def preprocess_image(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    edges = cv2.Canny(blur, 50, 150)\n",
        "    return edges\n",
        "\n",
        "# 車牌區域定位\n",
        "def locate_license_plate(image):\n",
        "    contours, _ = cv2.findContours(image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
        "\n",
        "    plate_contour = None\n",
        "\n",
        "    for contour in contours:\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
        "        if len(approx) == 4:\n",
        "            plate_contour = approx\n",
        "            break\n",
        "\n",
        "    return plate_contour\n",
        "\n",
        "# 字符分割\n",
        "def segment_characters(image, plate_contour):\n",
        "    mask = np.zeros(image.shape, np.uint8)\n",
        "    cv2.drawContours(mask, [plate_contour], 0, (255, 255, 255), -1)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "    return masked_image\n",
        "\n",
        "# 字符識別\n",
        "def recognize_characters(image):\n",
        "    custom_config = r'--oem 3 --psm 7'\n",
        "    text = pytesseract.image_to_string(image, config=custom_config)\n",
        "    return text\n",
        "\n",
        "# 讀取圖像\n",
        "image = cv2.imread('1.jpg')\n",
        "\n",
        "# 圖像預處理\n",
        "preprocessed_image = preprocess_image(image)\n",
        "\n",
        "# 車牌區域定位\n",
        "plate_contour = locate_license_plate(preprocessed_image)\n",
        "\n",
        "# 字符分割\n",
        "if plate_contour is not None:\n",
        "    segmented_image = segment_characters(preprocessed_image, plate_contour)\n",
        "\n",
        "    # 字符識別\n",
        "    text = recognize_characters(segmented_image)\n",
        "\n",
        "    # 在圖像上顯示識別結果\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(image, '識別結果: ' + text, (10, 30), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # 顯示結果\n",
        "    cv2.imshow('Original Image', image)\n",
        "    cv2.imshow('Plate', segmented_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Q3ON4X34OT9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6\n"
      ],
      "metadata": {
        "id": "o7b88FXuQ3oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 資料收集和標註\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # 讀取資料集中的圖像和標籤\n",
        "    for filename in os.listdir(data_dir):\n",
        "        if filename.endswith('1.jpg'):\n",
        "            image_path = os.path.join(data_dir, filename)\n",
        "            label = filename.split('.')[0]  # 假設檔名即為標籤\n",
        "            image = cv2.imread(image_path)\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# 圖像預處理\n",
        "def preprocess_image(image):\n",
        "    # 實現圖像預處理的程式碼，例如灰度轉換、二值化、調整大小等\n",
        "\n",
        "    return preprocessed_image\n",
        "\n",
        "# 模型設計\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    # 添加卷積層和池化層\n",
        "    # model.add(Conv2D(...))\n",
        "    # model.add(MaxPooling2D(...))\n",
        "    # ...\n",
        "    # 添加全連接層\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(...))\n",
        "    # ...\n",
        "    # 添加輸出層\n",
        "    # model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# 訓練模型\n",
        "def train_model(images, labels):\n",
        "    # 將圖像和標籤轉換為NumPy數組\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # 將標籤進行One-Hot編碼\n",
        "    num_classes = len(np.unique(labels))\n",
        "    labels = to_categorical(labels, num_classes)\n",
        "\n",
        "    # 將資料集分為訓練集和驗證集\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 圖像預處理\n",
        "    train_images = [preprocess_image(image) for image in train_images]\n",
        "    val_images = [preprocess_image(image) for image in val_images]\n",
        "\n",
        "    # 建立模型\n",
        "    input_shape = train_images[0].shape\n",
        "    model = create_model(input_shape, num_classes)\n",
        "\n",
        "    # 編譯模型\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 訓練模型\n",
        "    model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10, batch_size=32)\n",
        "\n",
        "    return model\n",
        "\n",
        "# 預測\n",
        "def predict(model, image):\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    # 使用訓練好的模型進行預測\n",
        "    # prediction = model.predict(np.array([preprocessed_image]))\n",
        "    # ...\n",
        "\n",
        "# 主程式\n",
        "data_dir = '/content/dataset'\n",
        "images, labels = load_data(data_dir)\n",
        "model = train_model(images, labels)\n",
        "\n",
        "# 測試預測\n",
        "test_image = cv2.imread('test.jpg')\n",
        "predict(model, test_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "-deNjKXhQ49D",
        "outputId": "a7f2783a-b77d-4180-d505-a1d1e10f458c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-440fc03b3b92>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m# 主程式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-440fc03b3b92>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 讀取資料集中的圖像和標籤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = os.path.join(os.getcwd(), 'dataset')\n",
        "print(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH9VQbPCSyIR",
        "outputId": "0f73266e-7223-485f-bddd-1327f6b72b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = os.path.join('/content', 'dataset')\n",
        "print(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSW3QcylS69b",
        "outputId": "22d1307f-c7ef-4a55-953e-ade672d8d76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/dataset'\n",
        "print(os.listdir(data_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "NBKX2MUWTObM",
        "outputId": "a6663f0c-daa7-4643-90b7-1b25bc439fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-3f0958ceabad>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ToxWFMwTVKG",
        "outputId": "bccbf93c-1a3a-471a-d70d-1fe547e50278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXAC-DV2TXyB",
        "outputId": "ee7d6b96-600d-483e-fc0d-2395df00f855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', '.ipynb_checkpoints', '1.jpg', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 原始資料夾路徑\n",
        "source_dir = '原始資料夾路徑'\n",
        "\n",
        "# 目標資料夾路徑\n",
        "target_dir = '/content/dataset'\n",
        "\n",
        "# 移動資料夾\n",
        "shutil.move(source_dir, target_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "vsEXQxm5UC31",
        "outputId": "d72db928-d565-4a98-ec4e-3d980282adf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '原始資料夾路徑' -> '/content/dataset'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-f3d09173f622>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 移動資料夾\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '原始資料夾路徑'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# 獲取當前工作目錄的路徑\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# 原始資料夾路徑\n",
        "source_dir = os.path.join(current_dir, 'dataset')\n",
        "\n",
        "# 目標資料夾路徑\n",
        "target_dir = '/content/dataset'\n",
        "\n",
        "# 移動資料夾\n",
        "shutil.move(source_dir, target_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zh_wanaCUJ1i",
        "outputId": "061e38a1-6123-49c7-cf17-34c177e4a67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 獲取當前工作目錄的路徑\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# 資料夾名稱\n",
        "folder_name = 'dataset'\n",
        "\n",
        "# 資料夾路徑\n",
        "data_dir = os.path.join(current_dir, folder_name)"
      ],
      "metadata": {
        "id": "_E7UeEtvUbA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = '/content/dataset'\n",
        "if os.path.isdir(data_dir):\n",
        "    print(f\"{data_dir} 是一個有效的資料夾路徑\")\n",
        "else:\n",
        "    print(f\"{data_dir} 不是一個有效的資料夾路徑\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M_1vMxOWrhG",
        "outputId": "0f311b8d-e80a-46ec-a216-108e4b2b00c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset 不是一個有效的資料夾路徑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "print(f\"當前工作目錄：{current_dir}\")\n",
        "\n",
        "data_dir = os.path.join(current_dir, \"dataset\")\n",
        "if os.path.isdir(data_dir):\n",
        "    print(f\"{data_dir} 是一個有效的資料夾路徑\")\n",
        "else:\n",
        "    print(f\"{data_dir} 不是一個有效的資料夾路徑\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSPbpT-GW3hV",
        "outputId": "2976c996-15a3-4591-ec95-6b4012819be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "當前工作目錄：/content\n",
            "/content/dataset 不是一個有效的資料夾路徑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(data_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcUvQ1iEUh7A",
        "outputId": "82082454-068f-40d1-c9fa-7dcc1910438f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.ipynb_checkpoints', 'OneDrive_1_2023-10-16.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = '/content/dataset'\n",
        "file_list = os.listdir(data_dir)\n",
        "print(file_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LebP9p5YfB1",
        "outputId": "2da4b50e-d52e-4416-aa43-0fa9a68312ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.ipynb_checkpoints', 'OneDrive_1_2023-10-16.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!pip install tesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_Qg-_nwGH8o",
        "outputId": "71ff0803-cbc4-45e7-9953-f4bd04dea4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Collecting tesseract\n",
            "  Downloading tesseract-0.1.3.tar.gz (45.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-py3-none-any.whl size=45562550 sha256=7bd3925b415451e57973fbcb8157d9b0ecd35d504d74ceffc823df18d9b8e435\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c9/aa/698c579693e83fdda9ad6d6f0d8f61ed986e27925ef576f109\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "# 資料收集和標註\n",
        "def train_model(images, labels):\n",
        "    # 將圖像和標籤轉換為NumPy數組\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # 將標籤進行One-Hot編碼\n",
        "    num_classes = len(np.unique(labels))\n",
        "    processed_labels = []\n",
        "\n",
        "    for label in labels:\n",
        "        try:\n",
        "            processed_label = int(label)\n",
        "            processed_labels.append(processed_label)\n",
        "        except ValueError:\n",
        "            # 無法轉換為整數的標籤，可以根據需要進行處理，例如跳過或指定一個預設值\n",
        "            # 這裡我們將無法轉換的標籤設置為 -1\n",
        "            processed_labels.append(-1)\n",
        "\n",
        "    labels = np.array(processed_labels)\n",
        "\n",
        "    # 將資料集分為訓練集和驗證集\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 圖像預處理\n",
        "    train_images = [preprocess_image(image) for image in train_images]\n",
        "    val_images = [preprocess_image(image) for image in val_images]\n",
        "\n",
        "    # 建立模型\n",
        "    input_shape = train_images[0].shape\n",
        "    model = create_model(input_shape, num_classes)\n",
        "\n",
        "    # 編譯模型\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 訓練模型\n",
        "    model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10, batch_size=32)\n",
        "\n",
        "    return model\n",
        "\n",
        "# 圖像預處理\n",
        "def preprocess_image(image):\n",
        "    # 實現圖像預處理的程式碼，例如灰度轉換、二值化、調整大小等\n",
        "\n",
        "    return preprocessed_image\n",
        "\n",
        "# 模型設計\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    # 添加卷積層和池化層\n",
        "    # model.add(Conv2D(...))\n",
        "    # model.add(MaxPooling2D(...))\n",
        "    # ...\n",
        "    # 添加全連接層\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(...))\n",
        "    # ...\n",
        "    # 添加輸出層\n",
        "    # model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# 訓練模型\n",
        "def train_model(images, labels):\n",
        "    # 將圖像和標籤轉換為NumPy數組\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # 將標籤進行One-Hot編碼\n",
        "    num_classes = len(np.unique(labels))\n",
        "    processed_labels = []\n",
        "\n",
        "    for label in labels:\n",
        "        try:\n",
        "            processed_label = int(label)\n",
        "            processed_labels.append(processed_label)\n",
        "        except ValueError:\n",
        "            # 無法轉換為整數的標籤，可以根據需要進行處理，例如跳過或指定一個預設值\n",
        "            # 這裡我們將無法轉換的標籤設置為 -1\n",
        "            processed_labels.append(-1)\n",
        "\n",
        "    labels = np.array(processed_labels)\n",
        "\n",
        "    # 將資料集分為訓練集和驗證集\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 圖像預處理\n",
        "    train_images = [preprocess_image(image) for image in train_images]\n",
        "    val_images = [preprocess_image(image) for image in val_images]\n",
        "\n",
        "    # 建立模型\n",
        "    input_shape = train_images[0].shape\n",
        "    model = create_model(input_shape, num_classes)\n",
        "\n",
        "    # 編譯模型\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 訓練模型\n",
        "    model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10, batch_size=32)\n",
        "\n",
        "    return model\n",
        "# 預測\n",
        "def predict(model, image):\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    # 使用訓練好的模型進行預測\n",
        "    # prediction = model.predict(np.array([preprocessed_image]))\n",
        "    # ...\n",
        "\n",
        "# 主程式\n",
        "data_dir = '/content/dataset'\n",
        "images, labels = load_data(data_dir)\n",
        "model = train_model(images, labels)\n",
        "\n",
        "# 測試預測\n",
        "test_image = cv2.imread('test.jpg')\n",
        "predict(model, test_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "WJN_5-DOUvES",
        "outputId": "ff2f10a1-1ebe-4db3-84ac-c9121b652c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a7d41ec1b049>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# 主程式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(images, labels):\n",
        "    # 將圖像和標籤轉換為NumPy數組\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # 將標籤進行One-Hot編碼\n",
        "    num_classes = len(np.unique(labels))\n",
        "    processed_labels = []\n",
        "\n",
        "    for label in labels:\n",
        "        try:\n",
        "            processed_label = int(label)\n",
        "            processed_labels.append(processed_label)\n",
        "        except ValueError:\n",
        "            # 無法轉換為整數的標籤，可以根據需要進行處理，例如跳過或指定一個預設值\n",
        "            # 這裡我們將無法轉換的標籤設置為 -1\n",
        "            processed_labels.append(-1)\n",
        "\n",
        "    labels = np.array(processed_labels)\n",
        "\n",
        "    # 將資料集分為訓練集和驗證集\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 圖像預處理\n",
        "    train_images = [preprocess_image(image) for image in train_images]\n",
        "    val_images = [preprocess_image(image) for image in val_images]\n",
        "\n",
        "    # 建立模型\n",
        "    input_shape = train_images[0].shape\n",
        "    model = create_model(input_shape, num_classes)\n",
        "\n",
        "    # 編譯模型\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 訓練模型\n",
        "    model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10, batch_size=32)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Jfa1uatPefSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 資料收集和標註\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # 讀取資料集中的圖像和標籤\n",
        "    for filename in os.listdir(data_dir):\n",
        "        if filename.endswith('.jpg'):\n",
        "            image_path = os.path.join(data_dir, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "            images.append(image)\n",
        "            label = filename.split('.')[0]  # 假設圖像檔案名稱為標籤\n",
        "            labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# 圖像預處理\n",
        "def preprocess_image(image):\n",
        "    # 實現圖像預處理的程式碼，例如灰度轉換、二值化、調整大小等\n",
        "    # 在這裡添加相應的圖像預處理操作\n",
        "    # preprocessed_image = ...\n",
        "\n",
        "    return preprocessed_image\n",
        "\n",
        "# 模型設計\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    # 添加卷積層和池化層\n",
        "    # model.add(Conv2D(...))\n",
        "    # model.add(MaxPooling2D(...))\n",
        "    # ...\n",
        "    # 添加全連接層\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(...))\n",
        "    # ...\n",
        "    # 添加輸出層\n",
        "    # model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# 訓練模型\n",
        "def train_model(images, labels):\n",
        "    # 將圖像和標籤轉換為NumPy數組\n",
        "    images = np.array(images, dtype=object)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # 將標籤轉換為整數\n",
        "    unique_labels = np.unique(labels)\n",
        "    num_classes = len(unique_labels) + 1  # 加上額外的類別\n",
        "    label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
        "    processed_labels = []\n",
        "\n",
        "    for label in labels:\n",
        "        try:\n",
        "            processed_label = label_to_int[label]\n",
        "        except KeyError:\n",
        "            processed_label = num_classes - 1  # 將無法轉換的標籤設置為額外的類別\n",
        "        processed_labels.append(processed_label)\n",
        "\n",
        "    labels = np.array(processed_labels)\n",
        "\n",
        "    # 將資料集分為訓練集和驗證集\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 圖像預處理\n",
        "    train_images = [preprocess_image(image) for image in train_images]\n",
        "    val_images = [preprocess_image(image) for image in val_images]\n",
        "\n",
        "    # 建立模型\n",
        "    input_shape = train_images[0].shape\n",
        "    model = create_model(input_shape, num_classes)\n",
        "\n",
        "    # 編譯模型\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 將標籤進行One-Hot編碼\n",
        "    train_labels = to_categorical(train_labels, num_classes, dtype='uint8')\n",
        "    val_labels = to_categorical(val_labels, num_classes, dtype='uint8')\n",
        "\n",
        "    # 訓練模型\n",
        "    model.fit(np.array(train_images), train_labels, validation_data=(np.array(val_images), val_labels), epochs=10, batch_size=16)\n",
        "\n",
        "    return model\n",
        "# 預測\n",
        "def predict(model, image):\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    # 使用訓練好的模型進行預測\n",
        "    prediction = model.predict(np.array([preprocessed_image]))\n",
        "    # ...\n",
        "\n",
        "# 主程式\n",
        "data_dir = '/content/dataset'\n",
        "images, labels = load_data(data_dir)\n",
        "model = train_model(images, labels)\n",
        "\n",
        "# 測試預測\n",
        "test_image = cv2.imread('test.jpg')\n",
        "predict(model, test_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "mmh9lI4ymW5g",
        "outputId": "64645c52-632f-4781-ddc6-0fa819d18fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-eb6d0495cb1e>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# 測試預測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-eb6d0495cb1e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# 訓練模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2100, in categorical_crossentropy\n        label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n\n    TypeError: Expected uint8, but got 0.0 of type 'float'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 資料收集和標註\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # 讀取資料集目錄中的圖像和標籤\n",
        "    for label_name in os.listdir(data_dir):\n",
        "        label_dir = os.path.join(data_dir, label_name)\n",
        "        if os.path.isdir(label_dir):\n",
        "            for image_name in os.listdir(label_dir):\n",
        "                image_path = os.path.join(label_dir, image_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                images.append(image)\n",
        "                labels.append(label_name)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# 圖像預處理\n",
        "def preprocess_image(image):\n",
        "    # 實現圖像預處理的程式碼，例如灰度轉換、二值化、調整大小等\n",
        "\n",
        "    return preprocessed_image\n",
        "\n",
        "# 模型設計\n",
        "def create_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    # 添加卷積層和池化層\n",
        "    # model.add(Conv2D(...))\n",
        "    # model.add(MaxPooling2D(...))\n",
        "    # ...\n",
        "    # 添加全連接層\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(...))\n",
        "    # ...\n",
        "    # 添加輸出層\n",
        "    # model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# 訓練模型\n",
        "def train_model(images, labels):\n",
        "    # 將圖像和標籤轉換為NumPy數組\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # 將標籤進行One-Hot編碼\n",
        "    num_classes = len(np.unique(labels))\n",
        "    processed_labels = []\n",
        "\n",
        "    for label in labels:\n",
        "        try:\n",
        "            processed_label = int(label)\n",
        "            processed_labels.append(processed_label)\n",
        "        except ValueError:\n",
        "            # 無法轉換為整數的標籤，可以根據需要進行處理，例如跳過或指定一個預設值\n",
        "            # 這裡我們將無法轉換的標籤設置為 -1\n",
        "            processed_labels.append(-1)\n",
        "\n",
        "    labels = np.array(processed_labels)\n",
        "\n",
        "    # 將資料集分為訓練集和驗證集\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 圖像預處理\n",
        "    train_images = [preprocess_image(image) for image in train_images]\n",
        "    val_images = [preprocess_image(image) for image in val_images]\n",
        "\n",
        "    # 建立模型\n",
        "    input_shape = train_images[0].shape\n",
        "    model = create_model(input_shape, num_classes)\n",
        "\n",
        "    # 編譯模型\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 訓練模型\n",
        "    model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10, batch_size=32)\n",
        "\n",
        "    return model\n",
        "\n",
        "# 預測\n",
        "def predict(model, image):\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    # 使用訓練好的模型進行預測\n",
        "    # prediction = model.predict(np.array([preprocessed_image]))\n",
        "    # ...\n",
        "\n",
        "\n",
        "# 主程式\n",
        "data_dir = '/content/dataset'\n",
        "images, labels = load_data(data_dir)\n",
        "model = train_model(images, labels)\n",
        "\n",
        "# 測試預測\n",
        "test_image = cv2.imread('test.jpg')\n",
        "predict(model, test_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "K9okjR4JHcLw",
        "outputId": "1393026b-3078-4c5a-f958-454976b687e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ab1357aa542a>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# 主程式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ab1357aa542a>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 讀取資料集目錄中的圖像和標籤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mlabel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "duXgtjqOHdRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}